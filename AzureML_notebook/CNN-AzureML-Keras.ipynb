{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Malaria predictor: Image classification problem\n",
    "\n",
    "# Convolutional Neural Network with Keras in Azure ML Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and configuring the Azure ML services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.33\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Azure values in global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"<SUBSCRIPTION_ID>\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"<RESOURCE_GROUP>\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"<WORKSPACE_NAME>\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"<WORKSPACE_REGION>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize workspace\n",
    "Initialize a Workspace object from the existing workspace you created in the Prerequisites step. Workspace.from_config() creates a workspace object from the details stored in config.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FMYBKYW9N to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Workspace configuration succeeded. Skip the workspace creation steps below\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Creating a new workspace below\")\n",
    "    # Create the workspace using the specified parameters\n",
    "    ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = True,\n",
    "                      exist_ok = True)\n",
    "    ws.get_details()\n",
    "\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MalariaCNNKeras\n",
      "Azure region: northeurope\n",
      "Subscription id: 83674078-c3fc-41e3-9cf6-93f29065e2a4\n",
      "Resource group: CapstoneIA\n"
     ]
    }
   ],
   "source": [
    "#ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the details of the workspace to a configuration file to the notebook library\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute resources for your training experiments\n",
    "Many of the sample notebooks use Azure ML managed compute (AmlCompute) to train models using a dynamically scalable pool of compute. In this section you will create default compute clusters for use by the other notebooks and any other operations you choose.\n",
    "\n",
    "To create a cluster, you need to specify a compute configuration that specifies the type of machine to be used and the scalability behaviors. Then you choose a name for the cluster that is unique within the workspace that can be used to address the cluster later.\n",
    "\n",
    "The cluster parameters are:\n",
    "\n",
    "vm_size - this describes the virtual machine type and size used in the cluster. All machines in the cluster are the same type. You can get the list of vm sizes available in your region by using the CLI command\n",
    "az vm list-skus -o tsv\n",
    "min_nodes - this sets the minimum size of the cluster. If you set the minimum to 0 the cluster will shut down all nodes while note in use. Setting this number to a value higher than 0 will allow for faster start-up times, but you will also be billed when the cluster is not in use.\n",
    "max_nodes - this sets the maximum size of the cluster. Setting this to a larger number allows for more concurrency and a greater distributed processing of scale-out jobs.\n",
    "To create a CPU cluster now, run the cell below. The autoscale settings mean that the cluster will scale down to 0 nodes when inactive and up to 4 nodes when busy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "#cpu_cluster_name = \"cpucluster\"\n",
    "cpu_cluster_name = \"ML-VM-DSVM\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    # \"STANDARD_DS12_V2\" \"STANDARD_D4_V2\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D12_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Open an Azure ML experiment\n",
    "Let's create an experiment named \"keras-malaria\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malaria\n",
      "[Experiment(Name: malaria,\n",
      "Workspace: MalariaCNNKeras)]\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './keras-malaria'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='malaria')\n",
    "print(exp.name)\n",
    "print(exp.list(ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Malaria dataset to default datastore\n",
    "A datastore is a place where data can be stored that is then made accessible to a Run either by means of mounting or copying the data to the compute target. A datastore can either be backed by an Azure Blob Storage or and Azure File Share (ADLS will be supported in the future). For simple data handling, each workspace provides a default datastore that can be used, in case the data is not already in Blob Storage or File Share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n this next step, we will upload the training and test set into the workspace's default datastore, which we will then later be mount on an AmlCompute cluster for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/x_images_arrays_zip_1000.npz\n",
      "Uploading ./data/y_infected_labels_1000.npz\n",
      "Uploaded ./data/y_infected_labels_1000.npz, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/x_images_arrays_zip_1000.npz, 2 files out of an estimated total of 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_b3879516944548e9b31877cc2fcb6b3c"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload(src_dir='./data', target_path='malaria', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default Compute resource\n",
    "You can create a compute target for training your model but we will use default AmlCompute type CPU as our  training compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.core.compute.amlcompute.AmlComputeStatus object at 0x7f7214f2b160>\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "#compute_target = ws.get_default_compute_target(type=\"CPU\")\n",
    "compute_target = ComputeTarget(ws, 'cpucluster')\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "#print(compute_target.get_status().serialize())\n",
    "print(compute_target.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6133d4de1138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_compute_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_status'"
     ]
    }
   ],
   "source": [
    "compute_target = ws.get_default_compute_target(type=\"CPU\")\n",
    "print(compute_target.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpucluster AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.core.compute.dsvm.DsvmCompute at 0x7f2cb80557b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the training files into the script folder\n",
    "- Important: Upload the most recent .py file to the current active directory before running the next command. It will move this file to the script_folder where the azure training job will get the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-malaria/train_cnn_raw_gen.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# the training logic is in the keras_mnist.py file.\n",
    "shutil.copy('./train_cnn_raw_gen.py', script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-malaria'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an azureml.train.dnn.TensorFlow estimator object, use the  compute target, and pass the mount-point of the datastore to the training code as a parameter. The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add keras package (for the Keras framework obviously), and matplotlib package for plotting a \"Loss vs. Accuracy\" chart and record it in run history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path('malaria').as_download(),\n",
    "    '--batch-size': 32,\n",
    "    '--x_filename': 'x_images_arrays_zip21765.npz',\n",
    "    '--y_filename': 'y_infected_labels21765.npz',\n",
    "    '--training_size': '21765',\n",
    "    '--n_epochs': 20\n",
    "}\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=cpu_cluster, \n",
    "                 pip_packages=['keras', 'matplotlib'],\n",
    "                 conda_packages=['scikit-learn'],\n",
    "                 entry_script='train_cnn_raw_gen.py', \n",
    "                 use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "\n",
    "Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about 5 minutes. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "Scaling: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about 5 minutes.\n",
    "\n",
    "Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the entry_script is executed. While the job is running, stdout and the ./logs folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "Post-Processing: The ./outputs folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget.\n",
    "\n",
    "Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c69f5be06f6483fb9796f0cf79d399d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also periodically check the status of the run object, and navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some metrics from the experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': [0.6947016944885254, 0.6735986909866333, 0.5722702510356903],\n",
       " 'Accuracy': [0.544125, 0.573125, 0.704875],\n",
       " 'Final test loss': 0.38306117510795595,\n",
       " 'Final test accuracy': 0.873,\n",
       " 'Training size': 10000.0,\n",
       " 'Accuracy vs Loss': 'aml://artifactId/Accuracy vs Loss.png'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'malaria_1558194666_179a3f01',\n",
       " 'target': 'cpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-05-18T15:51:17.677653Z',\n",
       " 'endTimeUtc': '2019-05-18T15:51:47.615513Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_04ffe2fa28e82945988e51c8d6a84351',\n",
       "  'ContentSnapshotId': 'e231c4de-654f-4bd2-ab39-63e7b73f1152',\n",
       "  'azureml.git.repository_uri': None,\n",
       "  'azureml.git.branch': None,\n",
       "  'azureml.git.commit': None,\n",
       "  'azureml.git.dirty': 'False',\n",
       "  'azureml.git.build_id': None,\n",
       "  'azureml.git.build_uri': None,\n",
       "  'mlflow.source.git.branch': None,\n",
       "  'mlflow.source.git.commit': None,\n",
       "  'mlflow.source.git.repoURL': None},\n",
       " 'runDefinition': {'script': 'train_cnn.py',\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_01a180b961394f52819fe2db7d7fea9f',\n",
       "   '--batch-size',\n",
       "   '16',\n",
       "   '--x_filename',\n",
       "   'x_images_arrays_zip_100.npz',\n",
       "   '--y_filename',\n",
       "   'y_infected_labels_100.npz'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpucluster',\n",
       "  'dataReferences': {'01a180b961394f52819fe2db7d7fea9f': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': 'malaria',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'autoPrepareEnvironment': True,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment malaria Environment',\n",
       "   'version': 'Autosave_2019-05-17T16:56:18Z_46381064',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['keras',\n",
       "        'matplotlib',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow==1.13.1',\n",
       "        'horovod==0.16.1']},\n",
       "      'scikit-learn']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'preparation': None,\n",
       "    'gpuSupport': False,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'packages': [{'group': 'com.microsoft.ml.spark',\n",
       "      'artifact': 'mmlspark_2.11',\n",
       "      'version': '0.12'}],\n",
       "    'precachePackages': False}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://malariacstoragef30815895.blob.core.windows.net/azureml/ExperimentRun/dcid.malaria_1558194666_179a3f01/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=b8VTWZWZl9IWKnJQXlFea%2BlR0e0ha25tZ3TPguLW3yM%3D&st=2019-05-18T15%3A46%3A36Z&se=2019-05-18T23%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://malariacstoragef30815895.blob.core.windows.net/azureml/ExperimentRun/dcid.malaria_1558194666_179a3f01/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=F9cQ3N9usFhOsyEGASBRJ0nki7PDyFNBCoattAcnoJU%3D&st=2019-05-18T15%3A46%3A36Z&se=2019-05-18T23%3A56%3A36Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://malariacstoragef30815895.blob.core.windows.net/azureml/ExperimentRun/dcid.malaria_1558194666_179a3f01/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=vF1%2BxUcWZpWj8%2FhhJNy0D0Kt5pnKIeKh6yt81AOLyVQ%3D&st=2019-05-18T15%3A46%3A36Z&se=2019-05-18T23%3A56%3A36Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://malariacstoragef30815895.blob.core.windows.net/azureml/ExperimentRun/dcid.malaria_1558194666_179a3f01/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=EZzygSTejcJobRjlwkEHZHuNbb4OqG7oKxLBWpuLXYM%3D&st=2019-05-18T15%3A46%3A36Z&se=2019-05-18T23%3A56%3A36Z&sp=r'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accuracy vs Loss.png',\n",
       " 'azureml-logs/55_batchai_execution.txt',\n",
       " 'azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/80_driver_log.txt',\n",
       " 'logs/azureml/azureml.log',\n",
       " 'outputs/model/model.h5',\n",
       " 'outputs/model/model.json']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
